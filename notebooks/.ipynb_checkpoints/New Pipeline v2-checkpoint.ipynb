{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pyspark.ml.feature as feature\n",
    "import pyspark.ml as ml\n",
    "import pyspark.ml.clustering as clustering\n",
    "import pyspark.sql as sql\n",
    "import pyspark.sql.functions as functions\n",
    "import pyspark.sql.types as types\n",
    "\n",
    "# Add all scripts from repository to local path. \n",
    "# From https://stackoverflow.com/a/35273613 .\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import twokenize\n",
    "import grid\n",
    "\n",
    "# From https://stackoverflow.com/a/36218558 .\n",
    "def sparkImport(module_name, module_directory):\n",
    "    \"\"\"\n",
    "    Convenience function. \n",
    "    \n",
    "    Tells the SparkContext sc (must already exist) to load\n",
    "    module module_name on every computational node before\n",
    "    executing an RDD. \n",
    "    \n",
    "    Args:\n",
    "        module_name: the name of the module, without \".py\". \n",
    "        module_directory: the path, absolute or relative, to\n",
    "                          the directory containing module\n",
    "                          module_Name. \n",
    "    \n",
    "    Returns: none. \n",
    "    \"\"\"\n",
    "    module_path = os.path.abspath(\n",
    "        module_directory + \"/\" + module_name + \".py\")\n",
    "    sc.addPyFile(module_path)\n",
    "\n",
    "sparkImport(\"twokenize\", \"..\")\n",
    "sparkImport('grid', '..')\n",
    "\n",
    "ss = sql.SparkSession.builder.appName(\"TwitterTokenizing\")\\\n",
    "                             .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151306\n",
      "[Row(lon=-74.27470828, lat=40.59844873, date=datetime.date(2016, 2, 1), tweet_tokens=[u'This', u'is', u'me', u',', u'YL', u'a', u'voice', u'from', u'JERSEY', u'..', u'And', u'im', u'pushin', u'this', u'#blackpowermovement', u'!', u'Links', u'in', u'my', u'bio', u'!', u'#BlackHistoryMonth', u'!', u'https://t.co/MLvAS9jIqj'])]\n"
     ]
    }
   ],
   "source": [
    "tweets_schema = types.StructType([\n",
    "  types.StructField('id', types.LongType()),\n",
    "  types.StructField('timestamp', types.LongType()),\n",
    "  types.StructField('postalCode', types.StringType()),\n",
    "  types.StructField('lon', types.DoubleType()),\n",
    "  types.StructField('lat', types.DoubleType()),\n",
    "  types.StructField('tweet', types.StringType()),\n",
    "  types.StructField('user_id', types.LongType()),\n",
    "  types.StructField('application', types.StringType()),\n",
    "  types.StructField('source', types.StringType())\n",
    "])\n",
    "tweets_df = ss.read.csv('tweets2.csv',\n",
    "                         escape='\"',\n",
    "                         header='true',\n",
    "                         schema=tweets_schema,\n",
    "                         mode='DROPMALFORMED')\n",
    "tweets_df = tweets_df.drop('id') \\\n",
    "                     .drop('postalCode') \\\n",
    "                     .drop('user_id') \\\n",
    "                     .drop('application') \\\n",
    "                     .drop('source')\n",
    "\n",
    "date_column = tweets_df['timestamp'].cast(types.TimestampType()) \\\n",
    "                                    .cast(types.DateType())\n",
    "tweets_df = tweets_df.withColumn('date', date_column) \\\n",
    "                     .drop('timestamp')\n",
    "\n",
    "date_to_column = functions.lit(datetime.datetime(2016, 3, 3))\n",
    "date_from_column = functions.lit(functions.date_sub(date_to_column, 31))\n",
    "tweets_df = tweets_df.filter(\n",
    "    ~(tweets_df.date < date_from_column)\n",
    "    & (tweets_df.date < date_to_column))\n",
    "\n",
    "sql_tokenize = functions.udf(\n",
    "    lambda tweet: twokenize.tokenize(tweet),\n",
    "    returnType=types.ArrayType(types.StringType()))\n",
    "tweets_df = tweets_df \\\n",
    "    .withColumn(\"tweet_tokens\", sql_tokenize(tweets_df.tweet)) \\\n",
    "    .drop('tweet')\n",
    "\n",
    "print(tweets_df.count())\n",
    "print(tweets_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n",
      "[Row(grid_square=1938, tokens=[u'#Retail', u'#Job', u'alert', u':', u'Assistant', u'Store', u'Manager', u'|', u'The', u'Vitamin', u'Shoppe', u'|', u'#NorthBergen', u',', u'NJ', u'https://t.co/oGkm5a2bWz', u'#Jobs', u'#Hiring', u\"I'm\", u'at', u'@Walmart', u'Supercenter', u'in', u'North', u'Bergen', u',', u'NJ', u'https://t.co/DvACYYIb5e', u'Want', u'to', u'work', u'in', u'#NorthBergen', u',', u'NJ', u'?', u'View', u'our', u'latest', u'opening', u':', u'https://t.co/JNE3Pv4jQR', u'#Retail', u'#Job', u'#Jobs', u'#Hiring', u'This', u'#Retail', u'#job', u'might', u'be', u'a', u'great', u'fit', u'for', u'you', u':', u'Assistant', u'Store', u'Manager', u'-', u'https://t.co/oGkm5a2bWz', u'#NorthBergen', u',', u'NJ', u'#Hiring', u'Key', u'Holder', u'-', u'The', u'Vitamin', u'Shoppe', u':', u'(', u'#NorthBergen', u',', u'NJ', u')', u'https://t.co/HQUWNVzJfg', u'#Job', u'#Jobs', u'#Hiring', u'#CareerArc', u'The', u'Vitamin', u'Shoppe', u':', u'Store', u'Manager', u'(', u'#NorthBergen', u',', u'NJ', u')', u'https://t.co/RnqTb5tWon', u'#Retail', u'#Job', u'#Jobs', u'#Hiring', u'#CareerArc', u'h8', u'on', u'us', u'@', u'Walmart', u'North', u'Bergen', u'https://t.co/p5ePZOf8qG', u'Health', u'Enthusiast', u'Part-Time', u'-', u'The', u'Vitamin', u'Shoppe', u':', u'(', u'#NorthBergen', u',', u'NJ', u')', u'https://t.co/tOb3Izf6RQ', u'#HealthWelfare', u'#Job', u'#Jobs', u'#Hiring', u'#CareerArc', u'#Retail', u'#Job', u'alert', u':', u'Assistant', u'Store', u'Manager', u'|', u'The', u'Vitamin', u'Shoppe', u'|', u'#NorthBergen', u',', u'NJ', u'https://t.co/EOFpIV6ptM', u'#Jobs', u'#Hiring', u\"We're\", u'#hiring', u'!', u'Read', u'about', u'our', u'latest', u'#job', u'opening', u'here', u':', u'Health', u'Enthusiast', u'Part-Time', u'-', u'https://t.co/YSq1MjcIW4', u'#NorthBergen', u',', u'NJ', u'#CareerArc', u'#NorthBergen', u',', u'NJ', u'#Job', u':', u'Key', u'Holder', u'at', u'The', u'Vitamin', u'Shoppe', u'https://t.co/bcBexLfq3K', u'#Jobs', u'#Hiring', u'Coooooold', u'morning', u'!', u'@', u'Walmart', u'North', u'Bergen', u'https://t.co/UIWnOyk8A9', u'Shopping', u'with', u'the', u'fam', u'at', u'Walmart', u',', u\"it's\", u'been', u'a', u'good', u'day', u'#jmrc', u'\\u2026', u'https://t.co/3fuRKSoIIE', u'The', u'Vitamin', u'Shoppe', u':', u'Store', u'Manager', u'(', u'#NorthBergen', u',', u'NJ', u')', u'https://t.co/JNE3Pv4jQR', u'#Retail', u'#Job', u'#Jobs', u'#Hiring', u'Interested', u'in', u'a', u'#Retail', u'#job', u'near', u'#NorthBergen', u',', u'NJ', u'?', u'This', u'could', u'be', u'a', u'great', u'fit', u':', u'https://t.co/oGkm5a2bWz', u'#Hiring', u\"We're\", u'#hiring', u'!', u'Read', u'about', u'our', u'latest', u'#job', u'opening', u'here', u':', u'Health', u'Enthusiast', u'Part-Time', u'-', u'https://t.co/YSq1MjcIW4', u'#NorthBergen', u',', u'NJ', u'#CareerArc', u'Key', u'Holder', u'-', u'The', u'Vitamin', u'Shoppe', u':', u'(', u'#NorthBergen', u',', u'NJ', u')', u'https://t.co/HQUWNVzJfg', u'#Job', u'#Jobs', u'#Hiring', u'#CareerArc', u'Health', u'Enthusiast', u'Part-Time', u'-', u'The', u'Vitamin', u'Shoppe', u':', u'(', u'#NorthBergen', u',', u'NJ', u')', u'https://t.co/tOb3Izf6RQ', u'#HealthWelfare', u'#Job', u'#Jobs', u'#Hiring', u\"We're\", u'#hiring', u'!', u'Click', u'to', u'apply', u':', u'Store', u'Manager', u'-', u'https://t.co/RnqTb5tWon', u'#Retail', u'#NorthBergen', u',', u'NJ', u'#Job', u'#Jobs', u'#CareerArc'])]\n"
     ]
    }
   ],
   "source": [
    "# Southwest corner of New York:\n",
    "# lat = 40.488320, lon = -74.290739\n",
    "# Northeast corner of New York:\n",
    "# lat = 40.957189, lon = -73.635679\n",
    "\n",
    "latlongrid = grid.LatLonGrid(\n",
    "    lat_min=40.488320,\n",
    "    lat_max=40.957189,\n",
    "    lon_min=-74.290739,\n",
    "    lon_max=-73.635679,\n",
    "    lat_step=grid.get_lon_delta(1000, (40.957189 - 40.488320)/2.0),\n",
    "    lon_step=grid.get_lat_delta(1000))\n",
    "\n",
    "# The only way to group elements and get a set of data (as far as I know) is by converting the DataFrame into an RDD. \n",
    "\n",
    "row_to_gridsquare_tokens = lambda row: (\n",
    "    latlongrid.grid_square_index(lat=row['lat'], lon=row['lon']),\n",
    "    row['tweet_tokens'])\n",
    "\n",
    "tokens_rdd = tweets_df.rdd.map(row_to_gridsquare_tokens) \\\n",
    "                          .reduceByKey(operator.concat)\n",
    "\n",
    "tokens_df_schema = types.StructType([\n",
    "    types.StructField('grid_square', types.IntegerType()),\n",
    "    types.StructField('tokens', types.ArrayType(types.StringType()))\n",
    "])\n",
    "tokens_df = ss.createDataFrame(tokens_rdd, schema=tokens_df_schema)\n",
    "\n",
    "print(tokens_df.count())\n",
    "print(tokens_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = feature.CountVectorizer(inputCol='tokens', outputCol='token_frequencies')\n",
    "lda = clustering.LDA().setFeaturesCol('token_frequencies').setK(10).setTopicDistributionCol('topic_distributions')\n",
    "pipeline = ml.Pipeline(stages=[count_vectorizer, lda])\n",
    "\n",
    "lda_model = pipeline.fit(tokens_df)\n",
    "topic_distributions = lda_model.transform(tokens_df)\n",
    "\n",
    "print(topic_distributions.count())\n",
    "print(topic_distributions.take(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark2.1.0 / PySpark",
   "language": "python",
   "name": "spark2.1.0_pyspark"
  },
  "language_info": {
   "codemirror_mode": "text/x-ipython",
   "file_extension": ".py",
   "mimetype": "text/x-ipython",
   "name": "python",
   "pygments_lexer": "python",
   "version": "2.7.11\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
