{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql as sql\n",
    "import pyspark.sql.types as types\n",
    "\n",
    "ss = sql.SparkSession.builder.appName(\"TwitterTokenizing\")\\\n",
    "                             .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'timestamp', 'postalCode', 'lon', 'lat', 'tweet', 'user_id', 'application', 'source']\n",
      "[Row(id=616018411009744896, timestamp=1435723208, postalCode=u'83.0', lon=-73.951206, lat=40.79435, tweet=u'Incident on #VariousLocalExpressBuses SB from 5th Avenue:106th Street to 5th Avenue: 57th Street http://t.co/KrLOmkAqcE', user_id=u'52272942', application=u'511NY-Tweets', source=u'511NY-Tweets')]\n"
     ]
    }
   ],
   "source": [
    "tweets_schema = types.StructType([\n",
    "  types.StructField('id', types.LongType()),\n",
    "  types.StructField('timestamp', types.LongType()),\n",
    "  types.StructField('postalCode', types.StringType()),\n",
    "  types.StructField('lon', types.DoubleType()),\n",
    "  types.StructField('lat', types.DoubleType()),\n",
    "  types.StructField('tweet', types.StringType()),\n",
    "  types.StructField('user_id', types.StringType()),\n",
    "  types.StructField('application', types.StringType()),\n",
    "  types.StructField('source', types.StringType())\n",
    "])\n",
    "tweets_df = ss.read.load(\"unprocessed_tweets.csv\",\n",
    "                         format=\"com.databricks.spark.csv\",\n",
    "                         header=\"true\",\n",
    "                         schema=tweets_schema,\n",
    "                         mode=\"DROPMALFORMED\")\n",
    "#tweets_df = tweets_df.drop('id') \\\n",
    "#                     .drop('postalCode') \\\n",
    "#                     .drop('user_id') \\\n",
    "#                     .drop('application') \\\n",
    "#                     .drop('source')\n",
    "\n",
    "print(tweets_df.columns)\n",
    "print(tweets_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Incident', u'on', u'#VariousLocalExpressBuses', u'SB', u'from', u'5th', u'Avenue', u':', u'106th', u'Street', u'to', u'5th', u'Avenue', u':', u'57th', u'Street', u'http://t.co/KrLOmkAqcE']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# From https://stackoverflow.com/a/36218558 .\n",
    "def sparkImport(module_name, module_directory):\n",
    "    \"\"\"\n",
    "    Convenience function. \n",
    "    \n",
    "    Tells the SparkContext sc (must already exist) to load\n",
    "    module module_name on every computational node before\n",
    "    executing an RDD. \n",
    "    \n",
    "    Args:\n",
    "        module_name: the name of the module, without \".py\". \n",
    "        module_directory: the path, absolute or relative, to\n",
    "                          the directory containing module\n",
    "                          module_Name. \n",
    "    \n",
    "    Returns: none. \n",
    "    \"\"\"\n",
    "    module_path = os.path.abspath(\n",
    "        module_directory + \"/\" + module_name + \".py\")\n",
    "    sc.addPyFile(module_path)\n",
    "\n",
    "# Add all scripts from repository to local path. \n",
    "# From https://stackoverflow.com/a/35273613 .\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import twokenize\n",
    "sparkImport(\"twokenize\", \"..\")\n",
    "\n",
    "example_tweet = u'Incident on #VariousLocalExpressBuses SB from 5th Avenue:106th Street to 5th Avenue: 57th Street http://t.co/KrLOmkAqcE'\n",
    "print(twokenize.tokenize(example_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'timestamp', 'postalCode', 'lon', 'lat', 'tweet', 'user_id', 'application', 'source', 'tokens']\n",
      "[Row(id=616018411009744896, timestamp=1435723208, postalCode=u'83.0', lon=-73.951206, lat=40.79435, tweet=u'Incident on #VariousLocalExpressBuses SB from 5th Avenue:106th Street to 5th Avenue: 57th Street http://t.co/KrLOmkAqcE', user_id=u'52272942', application=u'511NY-Tweets', source=u'511NY-Tweets', tokens=[u'Incident', u'on', u'#VariousLocalExpressBuses', u'SB', u'from', u'5th', u'Avenue', u':', u'106th', u'Street', u'to', u'5th', u'Avenue', u':', u'57th', u'Street', u'http://t.co/KrLOmkAqcE'])]\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as functions\n",
    "\n",
    "sql_tokenize = functions.udf(\n",
    "    lambda tweet: twokenize.tokenize(tweet),\n",
    "    returnType=types.ArrayType(types.StringType()))\n",
    "tweets_df = tweets_df.withColumn(\"tokens\",\n",
    "                                 sql_tokenize(tweets_df.tweet))\n",
    "\n",
    "print(tweets_df.columns)\n",
    "print(tweets_df.take(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark2.1.0 / PySpark",
   "language": "python",
   "name": "spark2.1.0_pyspark"
  },
  "language_info": {
   "codemirror_mode": "text/x-ipython",
   "file_extension": ".py",
   "mimetype": "text/x-ipython",
   "name": "python",
   "pygments_lexer": "python",
   "version": "2.7.11\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
